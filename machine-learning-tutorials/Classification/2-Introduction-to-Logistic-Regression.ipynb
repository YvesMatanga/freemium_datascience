{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42bb4f85",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2><br/>\n",
    "   <ul>    \n",
    "    <li>Prerequisites: - a probabilistic view of classification</li>\n",
    "    <li>Prerequisites: - The sigmoid function</li>\n",
    "    <li>Logistic regression: concept</li>\n",
    "    <li>Logistic regression: implementation</li>\n",
    "    <li>Classifications metrics</li>\n",
    "   </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289046c2",
   "metadata": {},
   "source": [
    "<h2>1. Prerequisites</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7143f4",
   "metadata": {},
   "source": [
    "<h3>1.1. A Probabilistic view of classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ecea1",
   "metadata": {},
   "source": [
    "``<b>Classification is the task of determining the probability of a feature vector to belong to a given class k, P(Y=k|X)</b>\". <br/><br/>Let's look at the datasets of 'health-diabetes' supplied in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72af438f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../datasets/Healthcare-Diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../datasets/Healthcare-Diabetes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../datasets/Healthcare-Diabetes.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../datasets/Healthcare-Diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad418e6f",
   "metadata": {},
   "source": [
    "Given a customer profile $x=[pregrancies=5, glucose=148, bloodPressure=72, ..., Age=43]$, what is the probability of\n",
    "\n",
    "$$P(Y=1|X=x) = ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58102cf9",
   "metadata": {},
   "source": [
    "and\n",
    "\n",
    "$$P(Y=0|X=x) = ?$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082455a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89402f29",
   "metadata": {},
   "source": [
    "$$P(Y=1|X=x) = 1 - P(Y=0|X=x)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3f00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fa954ee",
   "metadata": {},
   "source": [
    "If $P(Y=1|X=x)=0.76$ and consequently $P(Y=0|X=x)=0.24$, we will conclude that the current profile shows a strong indication that the person <b>has diabetes</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a6c72",
   "metadata": {},
   "source": [
    "Alternatively, if $P(Y=1|X=x)=0.36$ and consequently $P(Y=0|X=x)=0.64$, we will conclude that the current profile shows a strong indication that the person <b>does not have diabetes</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e5f68",
   "metadata": {},
   "source": [
    "So, then classification is the task of estimating the probability distribution <br/><br/> $$P(Y=1|X=x) = f(\\theta,x)$$  <br/>such that for any profile we can estimate the probability $p = P(Y=1|X=x) = f(\\theta,x) $,<br/><br/> and tells whether the class for the input feature $x$ is y=1 ($p \\geq 0.5$) or y=0 ($p < 0.5$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccf249",
   "metadata": {},
   "source": [
    "<h3>1.2. The sigmoid function</h3><br/>\n",
    "Observe the shape of the sigmoid function:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1+e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06a77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z_n = np.arange(-10,10,step=0.1)\n",
    "sig_z = 1/(1+np.exp(-z_n))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(z_n,sig_z)\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('sig(z)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349443d",
   "metadata": {},
   "source": [
    "Note!!! The function output values $sig(z)$ are bounded between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be2d45",
   "metadata": {},
   "source": [
    "<h2>2. Logistic regression: Concept</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e83565e",
   "metadata": {},
   "source": [
    " Logistic regression is a classification algorithm that works by trying to learn a function that approximates P(Y|X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02e5e6c",
   "metadata": {},
   "source": [
    "It makes the assumption that P(Y|X) can be <b>approximated as a sigmoid function applied to a linear combination</b> of input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f200f",
   "metadata": {},
   "source": [
    "$$ P(Y=1|X=x) = \\sigma(z), z = \\theta_0+\\sum_{i=1}^{n}\\theta_ix_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468dcf82",
   "metadata": {},
   "source": [
    "$$ P(Y=1|X=x) = \\frac{1}{1+e^{-(\\theta_0+\\theta_1x_1+\\theta_2x_2+....+\\theta_nx_n)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29e897",
   "metadata": {},
   "source": [
    "$$\n",
    "   log(\\frac{P}{1-P}) = \\theta_0+\\theta_1x_1+\\theta_2x_2+....+\\theta_nx_n\n",
    "$$\n",
    "\n",
    "This log function is called, the <b style=\"color:blue\">logit function</b> measuring the odd of an event to occur over the odd it does not occur. It is approximated to be a <b style=\"color:blue\">linear combination of features</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38941b21",
   "metadata": {},
   "source": [
    "The exact estimation of the logistic regression parameters are obtained using the <b>maximum likelihood estimation method</b> (not covered) leading to the obtention of the $\\theta$ parameters that will build the <b>logistic function</b> or <b>classification model<b/>. \n",
    " See this <a href=\"https://mlinsightscentral.com/index.php/logistic-regression/\">link for insights</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4926e4d",
   "metadata": {},
   "source": [
    "<h2>3. Python Implementation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ea5ae",
   "metadata": {},
   "source": [
    "<b>3.1. Feature/Target extraction</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5987be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 1:9]#get features\n",
    "y = df.iloc[:,[-1]]#get target variable\n",
    "#X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a32c8",
   "metadata": {},
   "source": [
    "<b>3.2. Feature Scaling</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Sc = StandardScaler()\n",
    "Sc.fit(X)\n",
    "X_d = Sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6590f",
   "metadata": {},
   "source": [
    "<b>3.3. Training - Test Data Split</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44914adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test,y_train,y_test = train_test_split(X_d,y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e8d20",
   "metadata": {},
   "source": [
    "<b>3.4 Model Building</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clf = LogisticRegression() #clf = classification\n",
    "clf.fit(X_train,y_train) #fit the data: MLE (Maximum Likelhood Estimation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b92bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "718d64df",
   "metadata": {},
   "source": [
    "<b>3.5 Classification predictions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15339b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_x = np.array([6,148,72,35,0,33.6,0.627,50]).reshape(1,-1)\n",
    "\"\"\"\n",
    "Pregnancies=6\n",
    "Glucose=148\n",
    "BloodPressure=72\n",
    "SkinThickness=35\n",
    "Insulin=0\n",
    "BMI=33.6\n",
    "DiabetesPedigreeFunction=0.627\n",
    "Age=50\n",
    "\"\"\"\n",
    "\n",
    "profile_x_sc  = Sc.transform(profile_x)#normalise the input\n",
    "\n",
    "predicted_class = clf.predict(profile_x_sc)\n",
    "prob_class = clf.predict_proba(profile_x_sc)\n",
    "\n",
    "print('Predicted_class:',predicted_class[0], ' Probability: P(Y=1|X=x)=',prob_class[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45236ad5",
   "metadata": {},
   "source": [
    "<h2>4. Asssessing the Performance of a classification model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5809a8",
   "metadata": {},
   "source": [
    "There are several metrics to verify the performance of a classification model starting with the <b>classification accuracy</b> and <b>confusion matrix<b/>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b2a9b",
   "metadata": {},
   "source": [
    "<h3>4.1 The confusion matrix</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceac5ba",
   "metadata": {},
   "source": [
    "The confusion matrix is a matrix that records the performance of a classification model on several terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbede1",
   "metadata": {},
   "source": [
    "<img src=\"media/cm.png\" width=\"500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471da5e",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>The <b>True Positive</b> is the number of data observations that had a class of 1 and that were correctly classified as 1.</li>\n",
    " <li>The <b>True Negative</b> is the number of data observations that had a class of 0 and that were correctly classified as 0.</li>\n",
    "    <li>The <b>False Positive</b> is the number of data observations that had a class of 0 and that were wrongly classified as 1.</li>\n",
    "    <li>The <b>False Negative</b> is the number of data observations that had a class of 1 and that were wrongly classified as 0.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53231702",
   "metadata": {},
   "source": [
    "<h3>4.1.1 Classification Accuracy</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0df0b",
   "metadata": {},
   "source": [
    "The classification accuracy is the proportion of correct predictions made by the model out of all data records.<br/><br/>\n",
    "$$\n",
    " Classification\\text{ }Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb68ba6",
   "metadata": {},
   "source": [
    "<h3>4.1.2 Recall</h3>\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{TP \\space + FN} = \\frac{TP}{Total \\space Actual \\space Positive}\n",
    "$$\n",
    "\n",
    "Recall, also known as <b style=\"color:blue\">sensitivity</b> or true positive rate, measures This tells the <b>ability of a model to classify the instances of a particular class correctly</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58885e96",
   "metadata": {},
   "source": [
    "<h3>4.1.3 Precision</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dc3ecf",
   "metadata": {},
   "source": [
    "$$\n",
    "Precision = \\frac{TP}{TP \\space + FP} = \\frac{TP}{Total \\space Predicted \\space Positive} \n",
    "$$\n",
    "\n",
    "Precision measures the accuracy of predictions made by the model.Â  Precision indicates how <b style=\"color:blue\">confident</b> we can be that it is actually positive. It is calculated as the ratio of true positive predictions to the total number of positive predictions made by the model. Precision answers the question: \"Of all the instances predicted as positive, how many were actually positive?\" It can also be applied to negative outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02007ae1",
   "metadata": {},
   "source": [
    "<h3>4.1.4 F1 score</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45511bc",
   "metadata": {},
   "source": [
    " $$\n",
    " F_1 = 2 \\times \\frac {Precision \\space \\times \\space Recall }{Precision \\space + \\space Recall }\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aa182c",
   "metadata": {},
   "source": [
    "The F1 score is the harmonic mean of precision and recall. It provides a single metric that balances both precision and recall. The F1 score reaches its best value at 1 (perfect precision and recall) and worst at 0. It incentivise model with good (balanced) precision and recall and penalises models with imbalanced precision and recall values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33d00c",
   "metadata": {},
   "source": [
    "<b style=\"color:blue\"> A good model must classify all classes equally well (recall) and misclassify as little as possible (precision) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2477bc5",
   "metadata": {},
   "source": [
    "<h3>4.2. Python Implementation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab7dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "# Create confusion matrix for the training set\n",
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "class_acc_train = (cm_train[0][0]+cm_train[1][1])/(cm_train[0][0]+cm_train[0][1]+cm_train[1][0]+cm_train[1][1])\n",
    "\n",
    "# Create heatmap - Test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(cm_train, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, square=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Train')\n",
    "plt.show()\n",
    "\n",
    "print('Training-set- classification accuracy:',class_acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778145f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred_test = clf.predict(X_test)\n",
    "# Create confusion matrix for the test set\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "class_acc_test = (cm_test[0][0]+cm_test[1][1])/(cm_test[0][0]+cm_test[0][1]+cm_test[1][0]+cm_test[1][1])\n",
    "\n",
    "# Create heatmap - Test set\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.heatmap(cm_train, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, square=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Test')\n",
    "plt.show()\n",
    "\n",
    "print('Test-set- classification accuracy:',class_acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02315a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "targets = ['no-diabetes','has-diabetes']\n",
    "\n",
    "print(classification_report(y_test,y_pred_test,target_names=targets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35a7362",
   "metadata": {},
   "source": [
    "<h2>5. Improving the performance of a model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2ff47",
   "metadata": {},
   "source": [
    "Tips to improve the performance of a model:\n",
    "<ul>\n",
    "    <li>Normalise or standardise your features</li>\n",
    "    <li>Perform feature selection</li>\n",
    "    <li>Class data equalisation</li>\n",
    "    <li>Hyperparameter tuning (if possible)</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
