{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3479f7eb",
   "metadata": {},
   "source": [
    "<h2>Support Vector Machines</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c3ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabe0096",
   "metadata": {},
   "source": [
    "<h4>1. Concept - Linear SVM</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab982d",
   "metadata": {},
   "source": [
    "Consider a classification problme with two features $x_1$ and $x_2$ as illustrated in the image below.\n",
    "<img src=\"Media/svm_classification.png\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6386fd4",
   "metadata": {},
   "source": [
    "A Support vector classifier aims to find an hyperplane ($n-1$ dimensional line) that will seperate the datapoints in two distinct classes. This hyperplane is computed using <b>optimisation theory</b> by search for the coefficient of the hyperplane that will <b>maximise the margin</b> between the hyperplane and its closest datapoints (i.e. <b>support vectors</b>)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d434298b",
   "metadata": {},
   "source": [
    "Hyperplane equation for n features: \n",
    "$$\n",
    "  y = f(w,x) = w_1x_1 + w_2x_2 + ...+w_{n-1}x_{n-1} + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000ea55",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Maximize:} \\quad \\frac{2}{\\|w\\|}\n",
    "\\\\\n",
    "\\text{Subject to:} \\quad y_i(w \\cdot x_i + b) \\geq 1 \\quad \\text{for all} \\ i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d698834",
   "metadata": {},
   "source": [
    "<b>is equivalent to </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cab58f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Minimize:} \\quad \\frac{1}{2} \\|w\\|^2\n",
    "\\\\\n",
    "\\text{Subject to:} \\quad y_i(w \\cdot x_i + b) \\geq 1 \\quad \\text{for all} \\ i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4fe65e",
   "metadata": {},
   "source": [
    "$$\n",
    "SVMClassifier(x_i) =\\begin{cases}\n",
    "   \\text{if } f(w,x_i) \\geq 0, \\text{assign class 1}\\\\\n",
    "    \\text{if } f(w,x_i) < 0, \\text{assign class 0}\\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f13a3",
   "metadata": {},
   "source": [
    "<h4>2. Linear SVM - Soft Margin</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd8fd3f",
   "metadata": {},
   "source": [
    "<img src=\"Media/soft_margin.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca74e1b3",
   "metadata": {},
   "source": [
    "Perfect separable datapoints are rare or not practical in the real-world. The concept of soft margin is introduced to accomodate such real world data context. Introduction of slack variables : $\\xi_i = $ deviation of a data point from being correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaea86d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Minimize:} \\quad \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^{N} \\xi_i\n",
    "\\\\\n",
    "\\text{Subject to:} \\quad y_i(w \\cdot x_i + b) \\geq 1 - \\xi_i \\quad \\text{for all} \\ i\n",
    "\\\\\n",
    "\\text{and} \\quad \\xi_i \\geq 0 \\quad \\text{for all} \\ i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d97c6",
   "metadata": {},
   "source": [
    "<b>C is a hyperparameter called the regularization parameter</b>. It controls the trade-off between maximizing the margin and minimizing the classification error. Higher values of C correspond to a harder margin (less tolerance for misclassification), while lower values allow for a softer margin (more tolerance for misclassification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8952e",
   "metadata": {},
   "source": [
    "SVM works smoothly for linear separable datapoints. However when the datapoints aren't linear separable,\n",
    "<b>Linear SVM is not effective</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f40aa",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <figcaption>Figure 2: Linearly Separable datapoints vs Nonlinear Seperable datapoints</figcaption>\n",
    "    <img src=\"Media/linear_vs_nonlinear_svm_datapoints.png\" alt=\"Figure 1\">\n",
    "    \n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a61b6",
   "metadata": {},
   "source": [
    "<h4>2. Concept - Nonlinear SVM:  Kernel-based SVM</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1647d3f",
   "metadata": {},
   "source": [
    "In order to mitigate the limitation of SVM with non separable datapoints, a Kernel transformation on the datapoins\n",
    "can be performed that transform the datapoints into a different space in which they are sperable.\n",
    "\n",
    "\n",
    "<img src=\"Media/kernel_transformation.png\" width=\"500px\">\n",
    "\n",
    "The <b>Kernel</b> in this case, is the transformation function. Kernels can be of different types: \n",
    "\n",
    "<ul>\n",
    "    <li>Radial Basis Kernel: $K(x,y) = exp\\{-\\frac{(x-y)^2}{2\\sigma^2}\\}$</li>\n",
    "    <li>Polynomial Kernel: $K(x,y) = (x^Ty + 1)^p$</li>\n",
    "    <li>Hyperbolic Tangent Kernel: $K(x,y) = tanh(kx^Ty+\\delta)$</li>\n",
    "    <li>etc.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec6b071",
   "metadata": {},
   "source": [
    "<h4>Example: Linear and Nonlinear SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "641cffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0   1            6      148             72             35        0  33.6   \n",
       "1   2            1       85             66             29        0  26.6   \n",
       "2   3            8      183             64              0        0  23.3   \n",
       "3   4            1       89             66             23       94  28.1   \n",
       "4   5            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../datasets/Healthcare-Diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db82deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 1:9]#get features\n",
    "y = df.iloc[:,[-1]]#get target variable\n",
    "\n",
    "#---Data Scaling\n",
    "Sc = StandardScaler()\n",
    "Sc.fit(X)\n",
    "X_d = Sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96dcd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Train - Test Split\n",
    "X_train, X_test,y_train,y_test = train_test_split(X_d,y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf2cc8",
   "metadata": {},
   "source": [
    "<h4>Linear SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2bf7d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "linear_svc = SVC(kernel='linear')\n",
    "linear_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test = linear_svc.predict(X_test)\n",
    "class_acc_linear_svm = metrics.accuracy_score(y_test,y_pred_test)#get classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18682bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM - Test Performance: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " no-diabetes       0.77      0.93      0.84       349\n",
      "has-diabetes       0.82      0.53      0.64       205\n",
      "\n",
      "    accuracy                           0.78       554\n",
      "   macro avg       0.80      0.73      0.74       554\n",
      "weighted avg       0.79      0.78      0.77       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "targets = ['no-diabetes','has-diabetes']\n",
    "\n",
    "print(\"Linear SVM - Test Performance: \\n\",classification_report(y_test,y_pred_test,target_names=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ad9af",
   "metadata": {},
   "source": [
    "<h4>Nonlinear SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e104cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF SVM - Test Performance: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " no-diabetes       0.82      0.95      0.88       349\n",
      "has-diabetes       0.88      0.63      0.74       205\n",
      "\n",
      "    accuracy                           0.83       554\n",
      "   macro avg       0.85      0.79      0.81       554\n",
      "weighted avg       0.84      0.83      0.82       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbf_svc = SVC(kernel='rbf')\n",
    "rbf_svc.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test_rbfsvm = rbf_svc.predict(X_test)\n",
    "class_acc_rbf_rbfsvm = metrics.accuracy_score(y_test,y_pred_test_rbfsvm)#get classification accuracy\n",
    "\n",
    "print(\"RBF SVM - Test Performance: \\n\",classification_report(y_test,y_pred_test_rbfsvm,target_names=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce63997",
   "metadata": {},
   "source": [
    "<h4>Hyperparameter Tuning - SVM</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04958695",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'),\n",
    "              'C':(0.25,0.75,1.0),\n",
    "              'gamma': (0.5,1,2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25f61874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--GridSearch: Exhaustive Search with Crossvalidation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "798ff44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'gamma': 2, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, parameters,cv=5)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c8c12c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-RBF SVM - Test Performance: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " no-diabetes       0.82      0.95      0.88       349\n",
      "has-diabetes       0.88      0.63      0.74       205\n",
      "\n",
      "    accuracy                           0.83       554\n",
      "   macro avg       0.85      0.79      0.81       554\n",
      "weighted avg       0.84      0.83      0.82       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rbf_svc_hyper = SVC(kernel='rbf')\n",
    "rbf_svc_hyper.fit(X_train,y_train)\n",
    "\n",
    "y_pred_test_hyper = rbf_svc.predict(X_test)\n",
    "class_acc_rbf_svm = metrics.accuracy_score(y_test,y_pred_test_hyper)#get classification accuracy\n",
    "\n",
    "print(\"Hyper-RBF SVM - Test Performance: \\n\",classification_report(y_test,y_pred_test_hyper,target_names=targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
