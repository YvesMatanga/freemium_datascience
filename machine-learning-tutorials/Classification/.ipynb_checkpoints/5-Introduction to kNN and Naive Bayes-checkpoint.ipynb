{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c39d005",
   "metadata": {},
   "source": [
    "<h2>Introduction to k-Nearest Neighbours and Naive Bayes</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "388b5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2389f7",
   "metadata": {},
   "source": [
    "<h2>1. The k-Nearest Neighbors algorithm</h2>\n",
    "\n",
    "The k-nearest neighbours (kNN) algorithm is a multi-task model used for regression and classification that bases its prediction scheme on the majority vote of k neighbours.\n",
    "\n",
    "<img src=\"Media/knn-illustration.png\" width=\"600px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0ab5a",
   "metadata": {},
   "source": [
    "<h3>1.1. kNN - Classification</h3>\n",
    "\n",
    "In a classification problem, kNN prediction is based on the majority votes of points around it:\n",
    "\n",
    "$$\n",
    "\\hat{y} = f(x) = \\text{argmax}_{y \\in Y} \\sum_{i=1}^{k} I(y_i = y)\n",
    "$$\n",
    "\n",
    "\n",
    "where $I(y_i = y)$ is the indicator function that equals 1 if $y_i$  is equal to y, and 0 otherwise, \n",
    "$\\hat{y}$ is the predicted class label for the new data point x, and $y_i$ are the class labels of the \n",
    "k nearest neighbors of x. <span style=\"color:blue;\">The predicted class label $\\hat{y_i}$ is the class label that occurs most frequently among the k nearest neighbors of the new data point x.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ee8c6",
   "metadata": {},
   "source": [
    "<h3>1.2. kNN - Regression</h3>\n",
    "\n",
    "In a regression problem, kNN prediction is based on the mean value of k-points closest to the point of interest.\n",
    "\n",
    "$$\n",
    " \\hat{y} = f(x) = \\frac{1}{k}\\sum_{j\\in N_k(x)}^{}y_j\n",
    "$$\n",
    "\n",
    "where $y_i$ are the target values of the k nearest neighbors of x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e32731e",
   "metadata": {},
   "source": [
    "The kNN algorithm yields good predictive results in many supervised learning problems. <span style=\"color:blue;\">The success of the \n",
    "method depends on the good estimation of k.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46f703",
   "metadata": {},
   "source": [
    "<h3>1.3. kNN - Python Implementation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "375a26ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0   1            6      148             72             35        0  33.6   \n",
       "1   2            1       85             66             29        0  26.6   \n",
       "2   3            8      183             64              0        0  23.3   \n",
       "3   4            1       89             66             23       94  28.1   \n",
       "4   5            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../datasets/Healthcare-Diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d52ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 1:9]#get features\n",
    "y = df.iloc[:,[-1]]#get target variable\n",
    "\n",
    "#---Data Scaling\n",
    "Sc = StandardScaler()\n",
    "Sc.fit(X)\n",
    "X_d = Sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7531b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Train - Test Split\n",
    "X_train, X_test,y_train,y_test = train_test_split(X_d,y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7318a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "k = 3 #number of neighbors\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k) #kNN model configuration\n",
    "\n",
    "knn_classifier.fit(X_train,y_train)\n",
    "y_pred_test = knn_classifier.predict(X_test)\n",
    "class_acc_knn = metrics.accuracy_score(y_test,y_pred_test)#get classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a9bc98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN (3) - Test Performance: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " no-diabetes       0.91      0.97      0.94       349\n",
      "has-diabetes       0.93      0.84      0.88       205\n",
      "\n",
      "    accuracy                           0.92       554\n",
      "   macro avg       0.92      0.90      0.91       554\n",
      "weighted avg       0.92      0.92      0.92       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "targets = ['no-diabetes','has-diabetes']\n",
    "\n",
    "print(\"kNN (%d) - Test Performance: \\n\"%k,classification_report(y_test,y_pred_test,target_names=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1f355",
   "metadata": {},
   "source": [
    "<h3>1.3.2 kNN - Hyperparameter tuning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89dc210c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_neighbors':(2,3,5,6,7)}\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn_clf, parameters,cv=5) #VALIDATION SET????\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efd50351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN (2) - Test Performance: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " no-diabetes       0.91      0.99      0.95       349\n",
      "has-diabetes       0.98      0.84      0.90       205\n",
      "\n",
      "    accuracy                           0.93       554\n",
      "   macro avg       0.94      0.91      0.93       554\n",
      "weighted avg       0.94      0.93      0.93       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimal_k = clf.best_params_['n_neighbors']\n",
    "knn_c = KNeighborsClassifier(n_neighbors=optimal_k)\n",
    "knn_c.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test_c = knn_c.predict(X_test)\n",
    "print(\"kNN (%d) - Test Performance: \\n\"%optimal_k,classification_report(y_test,y_pred_test_c,target_names=targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a60aca",
   "metadata": {},
   "source": [
    "<h2>2. The Naive Bayes</h2>\n",
    "\n",
    "The Naive Bayes classifier is a classification method that takes the assumption of independence in features to relax the Bayes theorem and build a classification method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e732f",
   "metadata": {},
   "source": [
    "<img src=\"Media/naive_bayes-768x419.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f56c80",
   "metadata": {},
   "source": [
    "<h3>2.1 The Bayes Theorem</h3>\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(A \\cap B) }{P(A)} = \\frac{P(A|B)P(B)}{P(A)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953fb45",
   "metadata": {},
   "source": [
    "The essence of classification in the probabilistic view is to estimate the probability of a feature vector to belong to a given class.\n",
    "\n",
    "$$\n",
    "P(Y=k|x_1,x_2,x_3,...x_n) = f(\\theta,x_1,x_2,x_3,...x_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef6f08",
   "metadata": {},
   "source": [
    "<h3>2.2 Building a Naive Bayes Classifier</\n",
    "    h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a783a",
   "metadata": {},
   "source": [
    "$$\n",
    "P(Y=k|X=[x_1,x_2,..x_n]) = \\frac{P( x_1 \\cap x_2 ..\\cap  x_n \\cap Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)} = \\frac{P(x_1|x_2,x_3..x_n,Y=k)P(x_2 ..\\cap  x_n \\cap Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f97c5",
   "metadata": {},
   "source": [
    "$$\n",
    "P(Y=k|x_1,x_2,..x_n) = \\frac{P(x_1|x_2,x_3..x_n,Y=k)P(x_2 ..\\cap  x_n \\cap Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)} =  \\frac{P(x_1|x_2,x_3..x_n,Y=k)P(x_2|x_3...x_n,Y=k)P(x_3 ..\\cap  x_n \\cap Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f4298",
   "metadata": {},
   "source": [
    "$$\n",
    "=\\frac{P(x_1|x_2,x_3..x_n,Y=k)P(x_2|x_3...x_n,Y=k)P(x_3 |..  x_n, Y=k)P( .. x_n, Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5edc84",
   "metadata": {},
   "source": [
    "$$\n",
    "P(Y=k|x_1,x_2,..x_n)   =..=\\frac{P(x_1|x_2,x_3..x_n,Y=k)P(x_2|x_3...x_n,Y=k)P(x_3 |..  x_n, Y=k)...P(x_n| Y=k)P(Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0d41b",
   "metadata": {},
   "source": [
    "<b>Assumption 1: conditional independence in features</b>\n",
    "\n",
    "$$\n",
    "P(x_i|Y=k, x_j) = P (x_i|Y=k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb46f42a",
   "metadata": {},
   "source": [
    "$$\n",
    "P(Y=k|x_1,x_2,..x_n)  =\\frac{P(x_1|Y=k)P(x_2|Y=k)P(x_3 |Y=k)...P(x_n| Y=k)P(Y=k)}{P(x_1 \\cap x_2 ...\\cap x_n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b82fb",
   "metadata": {},
   "source": [
    "This relaxation drastically simplifies the computation of the conditional probability P(Y|X) which now only depends on the conditional probabilities P(x_i|Y=k) and the joint probability of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d126b",
   "metadata": {},
   "source": [
    "<b>Simplication 2: disregard the joint probability of features P(x_1,x_2,..x_n) </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754f4a4",
   "metadata": {},
   "source": [
    "$$\n",
    "P(Y=k|x_1,x_2,..x_n) \\text{ } \\alpha\\text{ } P(x_1|Y=k)P(x_2|Y=k)P(x_3 |Y=k)...P(x_n| Y=k)P(Y=k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637d241",
   "metadata": {},
   "source": [
    "Thus the Naive Bayes classifier does not compute true probability but rather a probability-based score to assign a data point to the most probable class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a79116",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Naive Bayes Score }(Y=k|x_1,x_2,..x_n) = P(x_1|Y=k)P(x_2|Y=k)P(x_3 |Y=k)...P(x_n| Y=k)P(Y=k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da4ca3b",
   "metadata": {},
   "source": [
    "For a generic implementation of the classifier, the conditional probabilities P(x_i|Y=k) are estimated from the data using probability density functions, most commonly estimated to be normal (Gaussian Naive Bayes) or using kernel density functions (Kernel Naive Bayes) for more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bedccc",
   "metadata": {},
   "source": [
    "<h3>2.3 Python Implementation - NB</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d7796ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train,y_train)#train the classifier\n",
    "#get model prediction on train set and test set\n",
    "y_pred_test_nb = nb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3dc19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test Performance: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " no-diabetes       0.78      0.87      0.82       349\n",
      "has-diabetes       0.72      0.58      0.64       205\n",
      "\n",
      "    accuracy                           0.76       554\n",
      "   macro avg       0.75      0.72      0.73       554\n",
      "weighted avg       0.75      0.76      0.75       554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes - Test Performance: \\n\",classification_report(y_test,y_pred_test_nb,target_names=targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
