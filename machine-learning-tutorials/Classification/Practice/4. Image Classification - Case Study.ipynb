{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "022f0784",
   "metadata": {},
   "source": [
    "<h1>Image Classification Case-Study</h1>\n",
    "\n",
    "In this code challenge, you will practice how to use classification for image recognition.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "      <!-- Image 1 -->\n",
    "      <td>\n",
    "        <img src=\"../Media/bearfrontal0001.jpg\" alt=\"Image 1\">\n",
    "      </td>      \n",
    "      <td>\n",
    "        <img src=\"../Media/cat450a.jpg\" alt=\"Image 1\">\n",
    "      </td>  \n",
    "        <td>\n",
    "        <img src=\"../Media/0000000057.jpg\" alt=\"Image 1\">\n",
    "      </td>  \n",
    "        <td>\n",
    "        <img src=\"../Media/cattlefrontal0005.jpg\" alt=\"Image 1\">\n",
    "      </td>  \n",
    "    </tr>\n",
    "  </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23b940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python #please install opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae2841",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">1. Load the datasets and get the list of all animal classes</b>\n",
    "\n",
    "Hint:<br/>\n",
    "Use <b>os</b> library<br/>\n",
    "directories = [name for name in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30578c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6bbe7",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">2. Display an animal of each class </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da7faed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b2c64",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">3. Create a dataframe of records based on the image data and the existing class labels</b>\n",
    "\n",
    "<ol>\n",
    "    <li>Convert every image to grayscale (black and white)</li>\n",
    "    <li>Resize every image to the same size (30 x 30)</li>\n",
    "    <li>Convert the image matrix into an array of pixel features</li>\n",
    "    <li>Form your dataframe:<b> image_name, image_class, pixel_feat1,pixel_feat2,....pixel_featn</b></li>\n",
    "</ol>\n",
    "\n",
    "<b>Use opencv for grayscale conversion: <br/></b>\n",
    "image = cv2.imread(folder_path_detail+\"\\\\\"+file_name)  <br/>\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)<br/>\n",
    "resize_image = cv2.resize(gray_image,(new_width,new_height))<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2195213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>image_class</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_890</th>\n",
       "      <th>feat_891</th>\n",
       "      <th>feat_892</th>\n",
       "      <th>feat_893</th>\n",
       "      <th>feat_894</th>\n",
       "      <th>feat_895</th>\n",
       "      <th>feat_896</th>\n",
       "      <th>feat_897</th>\n",
       "      <th>feat_898</th>\n",
       "      <th>feat_899</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 902 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image_name, image_class, feat_0, feat_1, feat_2, feat_3, feat_4, feat_5, feat_6, feat_7, feat_8, feat_9, feat_10, feat_11, feat_12, feat_13, feat_14, feat_15, feat_16, feat_17, feat_18, feat_19, feat_20, feat_21, feat_22, feat_23, feat_24, feat_25, feat_26, feat_27, feat_28, feat_29, feat_30, feat_31, feat_32, feat_33, feat_34, feat_35, feat_36, feat_37, feat_38, feat_39, feat_40, feat_41, feat_42, feat_43, feat_44, feat_45, feat_46, feat_47, feat_48, feat_49, feat_50, feat_51, feat_52, feat_53, feat_54, feat_55, feat_56, feat_57, feat_58, feat_59, feat_60, feat_61, feat_62, feat_63, feat_64, feat_65, feat_66, feat_67, feat_68, feat_69, feat_70, feat_71, feat_72, feat_73, feat_74, feat_75, feat_76, feat_77, feat_78, feat_79, feat_80, feat_81, feat_82, feat_83, feat_84, feat_85, feat_86, feat_87, feat_88, feat_89, feat_90, feat_91, feat_92, feat_93, feat_94, feat_95, feat_96, feat_97, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 902 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "new_width = 30\n",
    "new_height = 30\n",
    "\n",
    "image_df = pd.DataFrame(columns=['image_name', 'image_class'] + [f'feat_{i}' for i in range(new_width*new_height)])\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2ad8f",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">4. Split the Data into Training/Test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd4b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a8a588",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">5. Build the Classification model(s)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea9744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62eba1f9",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">6. Compute the Confusion Matrix on the Test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597237d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dba5b73",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">7. Generate the Classification Report on the Test set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513e71a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cf68297",
   "metadata": {},
   "source": [
    "<b style=\"color:blue;\">8. Test the model performance on image of your choice</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42232148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
